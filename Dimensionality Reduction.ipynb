{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.decomposition as decompose\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "Images_path = \"C:\\\\Users\\\\Ahmad Beltagy\\\\PycharmProjects\\\\Sheet2\\\\orl_faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImages():\n",
    "    matrix = []\n",
    "    labels = []\n",
    "    for i in range(1, 41, 1):\n",
    "        for j in range(1, 11, 1):\n",
    "            img = mpimg.imread(Images_path+\"\\\\s\" + str(i) + \"\\\\\" + str(\n",
    "                j) + \"\" + \".pgm\", format=\"pgm\")\n",
    "#             print(\"image is \",img)\n",
    "            row = np.reshape(img, 10304)\n",
    "#             print(\"row is \",row)\n",
    "            labels.append(i)\n",
    "            matrix.append(row)\n",
    "    return matrix , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitIntoTrainingAndTesting(matrix,labels):\n",
    "    trainingSet = []\n",
    "    trainingLabels = []\n",
    "    testingSet = []\n",
    "    testingLabels = []\n",
    "\n",
    "    for testing in range(0, 400, 2):\n",
    "        testingSet.append(matrix[testing])\n",
    "        testingLabels.append(labels[testing])\n",
    "\n",
    "    for training in range(1, 401, 2):\n",
    "        trainingSet.append(matrix[training])\n",
    "        trainingLabels.append(labels[training])\n",
    "\n",
    "    return trainingSet , trainingLabels , testingSet , testingLabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseEigenValues(eigenValues , alpha):\n",
    "    total = sum(eigenValues)\n",
    "    counter = 0\n",
    "    explainedVariance = 0\n",
    "    while(explainedVariance <= alpha):\n",
    "        counter = counter + 1\n",
    "        explainedVariance = sum(eigenValues[0:counter]) / total\n",
    "        #print(explainedVariance)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(dataMatrix , alpha):\n",
    "    # mean = np.mean(dataMatrix, axis=0)\n",
    "    cov = np.cov(dataMatrix.transpose() , bias=True)\n",
    "    #print(\"Covariance matrix \\n\",cov)\n",
    "    eigenValues , eigenVectors = np.linalg.eigh(cov)\n",
    "    \n",
    "    index = eigenValues.argsort()[::-1]\n",
    "    \n",
    "    eigenValues = eigenValues[index]\n",
    "    \n",
    "    numberOfEigenValues = chooseEigenValues(eigenValues, alpha)\n",
    "    \n",
    "    print(\"number of chosen eigenValues is \",numberOfEigenValues)\n",
    "    \n",
    "    desiredVectors = eigenVectors.transpose()\n",
    "    desiredVectors = desiredVectors[index][:numberOfEigenValues]\n",
    "    desiredVectors = desiredVectors.transpose()\n",
    "    \n",
    "    return desiredVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_Accuaracy(trainingSet, trainingLabels, testingSet, testingLabels, projectionMatrix):\n",
    "    \n",
    "    TrainingSetProjection = np.dot(trainingSet , projectionMatrix)\n",
    "    TestingSetProjection  = np.dot(testingSet , projectionMatrix) \n",
    "    print(\"projection of training Set size is : \",len(TrainingSetProjection),\" x \",len(TrainingSetProjection[0]))\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    \n",
    "    neigh.fit(TrainingSetProjection,trainingLabels)\n",
    "    \n",
    "    #print(neigh.score(X=TrainingSetProjection,y=trainingLabels, sample_weight=None))\n",
    "    test_pred = neigh.predict(TestingSetProjection)\n",
    "    \n",
    "    print('confusion matrix ',confusion_matrix(testingLabels, test_pred))  \n",
    "    print(classification_report(testingLabels, test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(dataMatrix):\n",
    "    totalMean = np.mean(dataMatrix,axis=0)\n",
    "    temparray = []\n",
    "    meanList = []\n",
    "    CenteredData = []\n",
    "    meanDiff = []\n",
    "    SMatrix = []\n",
    "    S = []\n",
    "    print()\n",
    "    #calculates mean for each class\n",
    "    for i in range(0,40,1):\n",
    "        temparray.append(dataMatrix[i*5])\n",
    "        temparray.append(dataMatrix[i*5 +1])\n",
    "        temparray.append(dataMatrix[i*5 +2])\n",
    "        temparray.append(dataMatrix[i*5 +3])\n",
    "        temparray.append(dataMatrix[i*5 +4])\n",
    "        meanList.append(np.mean(np.array(temparray), axis=0))\n",
    "        meanDiff.append(meanList[i] - totalMean)\n",
    "        SMatrix.append(5*np.outer(meanDiff,meanDiff))\n",
    "        temparray = []\n",
    "        meanDiff = []\n",
    "        \n",
    "        \n",
    "    B = sum(SMatrix)\n",
    "   \n",
    "    \n",
    "    \n",
    "    #Centers the Data\n",
    "    for j in range(0,40,1):\n",
    "        CenteredData.append(dataMatrix[j*5] - meanList[j])\n",
    "        CenteredData.append(dataMatrix[j*5 +1] - meanList[j])\n",
    "        CenteredData.append(dataMatrix[j*5 +2] - meanList[j])\n",
    "        CenteredData.append(dataMatrix[j*5 +3] - meanList[j])\n",
    "        CenteredData.append(dataMatrix[j*5 +4] - meanList[j])\n",
    "        \n",
    "    CenteredData = np.array(CenteredData)\n",
    "    \n",
    "    return B , CenteredData    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEigenLDA(S, B):\n",
    "    sInverse = np.linalg.pinv(S)\n",
    "    \n",
    "    print()\n",
    "    eigenValues , eigenVectors = np.linalg.eig(np.matmul(sInverse,B))\n",
    "    \n",
    "    \n",
    "    index = eigenValues.argsort()[::-1]\n",
    "    \n",
    "    eigenValues = eigenValues[index]\n",
    "    print(\"sorted eigenValues \\n\",eigenValues)\n",
    "    \n",
    "    numberOfEigenValues = 39\n",
    "    \n",
    "    print(eigenVectors)\n",
    "    \n",
    "    desiredVectors = eigenVectors.transpose()\n",
    "    print(desiredVectors)\n",
    "    desiredVectors = desiredVectors[index][:numberOfEigenValues]\n",
    "    desiredVectors = desiredVectors.transpose()\n",
    "    print(desiredVectors)\n",
    "    return desiredVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_Accuaracy(trainingSet, trainingLabels, testingSet, testingLabels, projectionMatrix):\n",
    "    \n",
    "    TrainingSetProjection = np.dot(trainingSet , projectionMatrix)\n",
    "    TestingSetProjection  = np.dot(testingSet , projectionMatrix) \n",
    "    print(\"projection of training Set size is : \",len(TrainingSetProjection),\" x \",len(TrainingSetProjection[0]))\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    \n",
    "    neigh.fit(TrainingSetProjection,trainingLabels)\n",
    "    \n",
    "    #print(neigh.score(X=TrainingSetProjection,y=trainingLabels, sample_weight=None))\n",
    "    test_pred = neigh.predict(TestingSetProjection)\n",
    "    \n",
    "    print(confusion_matrix(testingLabels, test_pred))  \n",
    "    print(classification_report(testingLabels, test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#main fn \n",
    "dataMatrix, Labels = readImages()\n",
    "\n",
    "#getting training set and testing Set\n",
    "trainingSet, trainingLabels, testingSet, testingLabels = splitIntoTrainingAndTesting(dataMatrix,Labels)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(trainingSet) \n",
    "scaler  = scaler.fit(trainingSet) \n",
    "trainingSet = scaler.transform(trainingSet)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(testingSet) \n",
    "scaler  = scaler.fit(testingSet) \n",
    "testingSet = scaler.transform(testingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for alpha 0.8\n",
      "number of chosen eigenValues is  35\n",
      "projection of training Set size is :  200  x  35\n",
      "confusion matrix  [[3 1 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 5 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.62      1.00      0.77         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.71      1.00      0.83         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       0.83      1.00      0.91         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       0.71      1.00      0.83         5\n",
      "          16       0.83      1.00      0.91         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      0.80      0.89         5\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       1.00      1.00      1.00         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      0.80      0.89         5\n",
      "          32       1.00      0.80      0.89         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      0.60      0.75         5\n",
      "          36       1.00      0.60      0.75         5\n",
      "          37       1.00      1.00      1.00         5\n",
      "          38       0.83      1.00      0.91         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.94      0.93      0.93       200\n",
      "weighted avg       0.94      0.93      0.93       200\n",
      "\n",
      "\n",
      "for alpha 0.85\n",
      "number of chosen eigenValues is  51\n",
      "projection of training Set size is :  200  x  51\n",
      "confusion matrix  [[3 1 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 5 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.62      1.00      0.77         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.71      1.00      0.83         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       0.83      1.00      0.91         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      0.80      0.89         5\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       1.00      1.00      1.00         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      0.80      0.89         5\n",
      "          32       1.00      1.00      1.00         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      0.80      0.89         5\n",
      "          36       0.75      0.60      0.67         5\n",
      "          37       1.00      1.00      1.00         5\n",
      "          38       0.83      1.00      0.91         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.95      0.94      0.94       200\n",
      "weighted avg       0.95      0.94      0.94       200\n",
      "\n",
      "\n",
      "for alpha 0.9\n",
      "number of chosen eigenValues is  75\n",
      "projection of training Set size is :  200  x  75\n",
      "confusion matrix  [[3 1 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 5 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.62      1.00      0.77         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.71      1.00      0.83         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       0.71      1.00      0.83         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      0.80      0.89         5\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       1.00      1.00      1.00         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      0.80      0.89         5\n",
      "          32       1.00      1.00      1.00         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      0.80      0.89         5\n",
      "          36       1.00      0.60      0.75         5\n",
      "          37       1.00      1.00      1.00         5\n",
      "          38       0.83      1.00      0.91         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.95      0.94      0.94       200\n",
      "weighted avg       0.95      0.94      0.94       200\n",
      "\n",
      "\n",
      "for alpha 0.95\n",
      "number of chosen eigenValues is  115\n",
      "projection of training Set size is :  200  x  115\n",
      "confusion matrix  [[3 1 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 4 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.62      1.00      0.77         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       0.71      1.00      0.83         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      0.80      0.89         5\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       1.00      1.00      1.00         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       0.83      1.00      0.91         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       0.83      1.00      0.91         5\n",
      "          31       1.00      0.80      0.89         5\n",
      "          32       1.00      1.00      1.00         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      0.80      0.89         5\n",
      "          36       1.00      0.80      0.89         5\n",
      "          37       1.00      1.00      1.00         5\n",
      "          38       0.80      0.80      0.80         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.95      0.94      0.94       200\n",
      "weighted avg       0.95      0.94      0.94       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.8,0.85,0.9,0.95]\n",
    "\n",
    "for i in alpha:\n",
    "    print(\"for alpha\",i)\n",
    "    projectionMatrix = PCA(np.array(trainingSet), i)\n",
    "    PCA_Accuaracy(trainingSet,trainingLabels,testingSet,testingLabels,projectionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B MATRIX \n",
      " [[13.3008265  12.40961126 13.20372209 ... -1.53122996 -0.80784039\n",
      "  -0.58240453]\n",
      " [12.40961126 11.60247372 12.32560284 ... -1.3690459  -0.70891897\n",
      "  -0.51409522]\n",
      " [13.20372209 12.32560284 13.14507067 ... -1.41604199 -0.70504932\n",
      "  -0.49405978]\n",
      " ...\n",
      " [-1.53122996 -1.3690459  -1.41604199 ...  8.03169455  7.37121988\n",
      "   7.29313095]\n",
      " [-0.80784039 -0.70891897 -0.70504932 ...  7.37121988  7.22705997\n",
      "   7.08650647]\n",
      " [-0.58240453 -0.51409522 -0.49405978 ...  7.29313095  7.08650647\n",
      "   7.09802519]]\n",
      "S MATRIX and dimensions  10304 x 10304 \n",
      " [[ 1.61098988  1.44660588  1.54742495 ... -0.14105547 -0.13070796\n",
      "   0.02006253]\n",
      " [ 1.44660588  1.43095418  1.46742388 ... -0.0902315  -0.08248016\n",
      "   0.06255179]\n",
      " [ 1.54742495  1.46742388  1.62238679 ... -0.12314513 -0.03436314\n",
      "   0.127157  ]\n",
      " ...\n",
      " [-0.14105547 -0.0902315  -0.12314513 ...  3.11574404  1.94810854\n",
      "   1.49967775]\n",
      " [-0.13070796 -0.08248016 -0.03436314 ...  1.94810854  2.44058426\n",
      "   2.02809528]\n",
      " [ 0.02006253  0.06255179  0.127157   ...  1.49967775  2.02809528\n",
      "   2.55241643]]\n",
      "\n",
      "sorted eigenValues \n",
      " [ 2.23176506e+01+0.00000000e+00j  1.58635220e+01+0.00000000e+00j\n",
      "  1.01356007e+01+0.00000000e+00j ... -1.99525912e-15+2.77817455e-16j\n",
      " -1.99525912e-15-2.77817455e-16j -2.56917447e-15+0.00000000e+00j]\n",
      "[[-0.003916  +0.j          0.00926935+0.j          0.00270809+0.j\n",
      "  ... -0.00153184+0.00436824j  0.002998  +0.j\n",
      "   0.00271127+0.j        ]\n",
      " [-0.00719031+0.j          0.00593625+0.j          0.00117524+0.j\n",
      "  ...  0.00211623-0.00272808j -0.00013263+0.j\n",
      "  -0.00373783+0.j        ]\n",
      " [-0.00083882+0.j          0.01058951+0.j          0.00454142+0.j\n",
      "  ... -0.00261425+0.00263057j -0.00203632+0.j\n",
      "   0.00363532+0.j        ]\n",
      " ...\n",
      " [-0.03106023+0.j          0.0128866 +0.j          0.01656978+0.j\n",
      "  ... -0.00414833+0.00067383j -0.00488585+0.j\n",
      "   0.00442632+0.j        ]\n",
      " [-0.01770504+0.j         -0.00236813+0.j          0.02149612+0.j\n",
      "  ... -0.0003056 +0.00132098j -0.00056936+0.j\n",
      "  -0.00335644+0.j        ]\n",
      " [-0.03448055+0.j          0.00468858+0.j          0.00738866+0.j\n",
      "  ...  0.00351205-0.00272477j  0.00627139+0.j\n",
      "  -0.01557783+0.j        ]]\n",
      "[[-0.003916  +0.j         -0.00719031+0.j         -0.00083882+0.j\n",
      "  ... -0.03106023+0.j         -0.01770504+0.j\n",
      "  -0.03448055+0.j        ]\n",
      " [ 0.00926935+0.j          0.00593625+0.j          0.01058951+0.j\n",
      "  ...  0.0128866 +0.j         -0.00236813+0.j\n",
      "   0.00468858+0.j        ]\n",
      " [ 0.00270809+0.j          0.00117524+0.j          0.00454142+0.j\n",
      "  ...  0.01656978+0.j          0.02149612+0.j\n",
      "   0.00738866+0.j        ]\n",
      " ...\n",
      " [-0.00153184+0.00436824j  0.00211623-0.00272808j -0.00261425+0.00263057j\n",
      "  ... -0.00414833+0.00067383j -0.0003056 +0.00132098j\n",
      "   0.00351205-0.00272477j]\n",
      " [ 0.002998  +0.j         -0.00013263+0.j         -0.00203632+0.j\n",
      "  ... -0.00488585+0.j         -0.00056936+0.j\n",
      "   0.00627139+0.j        ]\n",
      " [ 0.00271127+0.j         -0.00373783+0.j          0.00363532+0.j\n",
      "  ...  0.00442632+0.j         -0.00335644+0.j\n",
      "  -0.01557783+0.j        ]]\n",
      "[[-0.003916  +0.j  0.00926935+0.j  0.00270809+0.j ... -0.00786907+0.j\n",
      "  -0.00659307+0.j  0.00147367+0.j]\n",
      " [-0.00719031+0.j  0.00593625+0.j  0.00117524+0.j ... -0.00176804+0.j\n",
      "  -0.00351501+0.j  0.00269085+0.j]\n",
      " [-0.00083882+0.j  0.01058951+0.j  0.00454142+0.j ... -0.002131  +0.j\n",
      "  -0.00473566+0.j  0.00715271+0.j]\n",
      " ...\n",
      " [-0.03106023+0.j  0.0128866 +0.j  0.01656978+0.j ...  0.01195634+0.j\n",
      "   0.0265704 +0.j  0.01071997+0.j]\n",
      " [-0.01770504+0.j -0.00236813+0.j  0.02149612+0.j ...  0.00635665+0.j\n",
      "  -0.01384538+0.j  0.00539789+0.j]\n",
      " [-0.03448055+0.j  0.00468858+0.j  0.00738866+0.j ...  0.00135394+0.j\n",
      "  -0.02094887+0.j  0.00996737+0.j]]\n",
      "projection of training Set size is :  200  x  39\n",
      "[[4 0 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 4 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.83      1.00      0.91         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       0.83      1.00      0.91         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      0.80      0.89         5\n",
      "          20       1.00      1.00      1.00         5\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       0.83      1.00      0.91         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       1.00      0.60      0.75         5\n",
      "          27       0.83      1.00      0.91         5\n",
      "          28       1.00      1.00      1.00         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      0.80      0.89         5\n",
      "          32       1.00      0.80      0.89         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      1.00      1.00         5\n",
      "          36       1.00      0.80      0.89         5\n",
      "          37       0.83      1.00      0.91         5\n",
      "          38       1.00      0.80      0.89         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.96      0.96      0.95       200\n",
      "weighted avg       0.96      0.95      0.95       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "B , CenteredData = LDA(np.array(trainingSet))\n",
    "S = np.zeros((10304,10304))\n",
    "tempMatrix = []\n",
    "temp = np.array([])\n",
    "\n",
    "print(\"B MATRIX \\n\",B)\n",
    "\n",
    "for j in range(0,40,1):\n",
    "    tempMatrix.append(CenteredData[j*5])\n",
    "    tempMatrix.append(CenteredData[j*5+1])\n",
    "    tempMatrix.append(CenteredData[j*5+2])\n",
    "    tempMatrix.append(CenteredData[j*5+3])\n",
    "    tempMatrix.append(CenteredData[j*5+4])\n",
    "    tempMatrix  = np.array(tempMatrix)\n",
    "    S = S + np.dot(tempMatrix.transpose(),tempMatrix)\n",
    "    temp = np.array([])\n",
    "    tempMatrix = []\n",
    "\n",
    "print(\"S MATRIX and dimensions \",len(S),\"x\",len(S[0]),\"\\n\",S)    \n",
    "projectionMatrix = calculateEigenLDA(S, B)\n",
    "LDA_Accuaracy(trainingSet,trainingLabels,testingSet,testingLabels,np.real(projectionMatrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
